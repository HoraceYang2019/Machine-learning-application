{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#from preamble import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability Calibration\n",
    "https://axk51013.medium.com/%E6%A8%A1%E5%9E%8B%E4%BF%A1%E5%BF%83%E7%9A%84%E6%9C%AC%E8%B3%AA-probability-calibration-cbc680a44efa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create a synthetic dataset\n",
    "X, y = make_blobs(random_state=0)\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "# instantiate a model and fit it to the training set\n",
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "# evaluate the model on the test set\n",
    "print(\"Test set score: {:.2f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Validation in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Cross-validation scores: [0.96666667 1.         0.93333333 0.96666667 1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, GroupKFold\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "iris = load_iris()\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "scores = cross_val_score(logreg, iris.data, iris.target)\n",
    "print(GroupKFold().n_splits)\n",
    "\n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1.         0.93333333 1.         1.         0.93333333 0.93333333\n",
      " 0.93333333 1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=10)\n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score: 0.97\n"
     ]
    }
   ],
   "source": [
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00708914, 0.00891805, 0.0070014 , 0.00699902, 0.00600052]),\n",
       " 'score_time': array([0.        , 0.00099945, 0.        , 0.00099993, 0.        ]),\n",
       " 'test_score': array([0.96666667, 1.        , 0.93333333, 0.96666667, 1.        ]),\n",
       " 'train_score': array([0.96666667, 0.96666667, 0.98333333, 0.98333333, 0.975     ])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "res = cross_validate(logreg, iris.data, iris.target, cv=5,\n",
    "                     return_train_score=True)\n",
    "display(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008918</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.007089    0.000000    0.966667     0.966667\n",
       "1  0.008918    0.000999    1.000000     0.966667\n",
       "2  0.007001    0.000000    0.933333     0.983333\n",
       "3  0.006999    0.001000    0.966667     0.983333\n",
       "4  0.006001    0.000000    1.000000     0.975000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean times and scores:\n",
      " fit_time       0.007202\n",
      "score_time     0.000400\n",
      "test_score     0.973333\n",
      "train_score    0.975000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "res_df = pd.DataFrame(res)\n",
    "display(res_df)\n",
    "print(\"Mean times and scores:\\n\", res_df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Benefits of Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K-Fold cross-validation and other strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris labels:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "print(\"Iris labels:\\n{}\".format(iris.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More control over cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[1.         1.         0.86666667 0.93333333 0.83333333]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross-validation scores:\\n{}\".format(\n",
    "      cross_val_score(logreg, iris.data, iris.target, cv=kfold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3)\n",
    "print(\"Cross-validation scores:\\n{}\".format(\n",
    "    cross_val_score(logreg, iris.data, iris.target, cv=kfold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.875      0.875      0.85714286 1.\n",
      " 1.         0.85714286 1.         0.85714286 0.85714286 0.85714286\n",
      " 1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=20)\n",
    "print(\"Cross-validation scores:\\n{}\".format(\n",
    "    cross_val_score(logreg, iris.data, iris.target, cv=kfold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[0.98 0.96 0.96]\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "print(\"Cross-validation scores:\\n{}\".format(\n",
    "    cross_val_score(logreg, iris.data, iris.target, cv=kfold)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave-one-out cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cv iterations:  150\n",
      "Mean accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=loo)\n",
    "print(\"Number of cv iterations: \", len(scores))\n",
    "print(\"Mean accuracy: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle-split cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[0.98666667 0.94666667 0.97333333 0.96       0.98666667 0.96\n",
      " 0.96       0.96       0.93333333 0.97333333]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "shuffle_split = ShuffleSplit(test_size=.5, train_size=.5, n_splits=10)\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=shuffle_split)\n",
    "print(\"Cross-validation scores:\\n{}\".format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-validation with groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[0.75       0.6        0.66666667]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "# create synthetic dataset\n",
    "X, y = make_blobs(n_samples=12, random_state=0)\n",
    "# assume the first three samples belong to the same group,\n",
    "# then the next four, etc.\n",
    "groups = [0, 0, 0, 1, 1, 1, 1, 2, 2, 3, 3, 3]\n",
    "scores = cross_val_score(logreg, X, y, groups=groups, cv=GroupKFold(n_splits=3))\n",
    "print(\"Cross-validation scores:\\n{}\".format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 112   size of test set: 38\n",
      "Best score: 0.97\n",
      "Best parameters: {'C': 100, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# naive grid search implementation\n",
    "from sklearn.svm import SVC\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, random_state=0)\n",
    "print(\"Size of training set: {}   size of test set: {}\".format(\n",
    "      X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        # for each combination of parameters, train an SVC\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        # evaluate the SVC on the test set\n",
    "        score = svm.score(X_test, y_test)\n",
    "        # if we got a better score, store the score and parameters\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}\n",
    "\n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The danger of overfitting the parameters and the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 84   size of validation set: 28   size of test set: 38\n",
      "\n",
      "Best score on validation set: 0.96\n",
      "Best parameters:  {'C': 10, 'gamma': 0.001}\n",
      "Test set score with best parameters: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# split data into train+validation set and test set\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    iris.data, iris.target, random_state=0)\n",
    "# split train+validation set into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_trainval, y_trainval, random_state=1)\n",
    "print(\"Size of training set: {}   size of validation set: {}   size of test set:\"\n",
    "      \" {}\\n\".format(X_train.shape[0], X_valid.shape[0], X_test.shape[0]))\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        # for each combination of parameters, train an SVC\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        # evaluate the SVC on the validation set\n",
    "        score = svm.score(X_valid, y_valid)\n",
    "        # if we got a better score, store the score and parameters\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}\n",
    "\n",
    "# rebuild a model on the combined training and validation set,\n",
    "# and evaluate it on the test set\n",
    "svm = SVC(**best_parameters)\n",
    "svm.fit(X_trainval, y_trainval)\n",
    "test_score = svm.score(X_test, y_test)\n",
    "print(\"Best score on validation set: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: \", best_parameters)\n",
    "print(\"Test set score with best parameters: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, gamma=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, gamma=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, gamma=0.1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        # for each combination of parameters,\n",
    "        # train an SVC\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        # perform cross-validation\n",
    "        scores = cross_val_score(svm, X_trainval, y_trainval, cv=5)\n",
    "        # compute mean cross-validation accuracy\n",
    "        score = np.mean(scores)\n",
    "        # if we got a better score, store the score and parameters\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}\n",
    "# rebuild a model on the combined training and validation set\n",
    "svm = SVC(**best_parameters)\n",
    "svm.fit(X_trainval, y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter grid:\n",
      "{'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "print(\"Parameter grid:\\n{}\".format(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5,\n",
    "                          return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;gamma&#x27;: [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "             return_train_score=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;gamma&#x27;: [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "             return_train_score=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'gamma': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.97\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'gamma': 0.1}\n",
      "Best cross-validation score: 0.97\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "SVC(C=10, gamma=0.1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analyzing the result of cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.001}</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366403</td>\n",
       "      <td>0.022485</td>\n",
       "      <td>22</td>\n",
       "      <td>0.370787</td>\n",
       "      <td>0.370787</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.366092</td>\n",
       "      <td>0.005581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.01}</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366403</td>\n",
       "      <td>0.022485</td>\n",
       "      <td>22</td>\n",
       "      <td>0.370787</td>\n",
       "      <td>0.370787</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.366092</td>\n",
       "      <td>0.005581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.1}</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366403</td>\n",
       "      <td>0.022485</td>\n",
       "      <td>22</td>\n",
       "      <td>0.370787</td>\n",
       "      <td>0.370787</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.366092</td>\n",
       "      <td>0.005581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 1}</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366403</td>\n",
       "      <td>0.022485</td>\n",
       "      <td>22</td>\n",
       "      <td>0.370787</td>\n",
       "      <td>0.370787</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.366092</td>\n",
       "      <td>0.005581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 0.001, 'gamma': 10}</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366403</td>\n",
       "      <td>0.022485</td>\n",
       "      <td>22</td>\n",
       "      <td>0.370787</td>\n",
       "      <td>0.370787</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.366092</td>\n",
       "      <td>0.005581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.000598      0.000488           0.0008        0.000400   0.001   \n",
       "1       0.000800      0.000400           0.0004        0.000490   0.001   \n",
       "2       0.000800      0.000400           0.0002        0.000400   0.001   \n",
       "3       0.000600      0.000490           0.0004        0.000490   0.001   \n",
       "4       0.000823      0.000413           0.0002        0.000399   0.001   \n",
       "\n",
       "  param_gamma                        params  split0_test_score  \\\n",
       "0       0.001  {'C': 0.001, 'gamma': 0.001}           0.347826   \n",
       "1        0.01   {'C': 0.001, 'gamma': 0.01}           0.347826   \n",
       "2         0.1    {'C': 0.001, 'gamma': 0.1}           0.347826   \n",
       "3           1      {'C': 0.001, 'gamma': 1}           0.347826   \n",
       "4          10     {'C': 0.001, 'gamma': 10}           0.347826   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
       "0           0.347826           0.363636  ...         0.366403        0.022485   \n",
       "1           0.347826           0.363636  ...         0.366403        0.022485   \n",
       "2           0.347826           0.363636  ...         0.366403        0.022485   \n",
       "3           0.347826           0.363636  ...         0.366403        0.022485   \n",
       "4           0.347826           0.363636  ...         0.366403        0.022485   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0               22            0.370787            0.370787   \n",
       "1               22            0.370787            0.370787   \n",
       "2               22            0.370787            0.370787   \n",
       "3               22            0.370787            0.370787   \n",
       "4               22            0.370787            0.370787   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.366667            0.366667            0.355556   \n",
       "1            0.366667            0.366667            0.355556   \n",
       "2            0.366667            0.366667            0.355556   \n",
       "3            0.366667            0.366667            0.355556   \n",
       "4            0.366667            0.366667            0.355556   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.366092         0.005581  \n",
       "1          0.366092         0.005581  \n",
       "2          0.366092         0.005581  \n",
       "3          0.366092         0.005581  \n",
       "4          0.366092         0.005581  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# convert to Dataframe\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "# show the first 5 rows\n",
    "display(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array(results.mean_test_score).reshape(6, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     17\u001b[0m     scores \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mcv_results_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar(\u001b[43mscores_image\u001b[49m, ax\u001b[38;5;241m=\u001b[39maxes\u001b[38;5;241m.\u001b[39mtolist())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scores_image' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1300x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 3, figsize=(13, 5))\n",
    "\n",
    "param_grid_linear = {'C': np.linspace(1, 2, 6),\n",
    "                     'gamma':  np.linspace(1, 2, 6)}\n",
    "\n",
    "param_grid_one_log = {'C': np.linspace(1, 2, 6),\n",
    "                      'gamma':  np.logspace(-3, 2, 6)}\n",
    "\n",
    "param_grid_range = {'C': np.logspace(-3, 2, 6),\n",
    "                    'gamma':  np.logspace(-7, -2, 6)}\n",
    "\n",
    "for param_grid, ax in zip([param_grid_linear, param_grid_one_log,\n",
    "                           param_grid_range], axes):\n",
    "    grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    scores = grid_search.cv_results_['mean_test_score'].reshape(6, 6)\n",
    "\n",
    "plt.colorbar(scores_image, ax=axes.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'kernel': ['rbf'],\n",
    "               'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "               'gamma': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "              {'kernel': ['linear'],\n",
    "               'C': [0.001, 0.01, 0.1, 1, 10, 100]}]\n",
    "print(\"List of grids:\\n{}\".format(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5,\n",
    "                          return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "# we display the transposed table so that it better fits on the page:\n",
    "display(results.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using different cross-validation strategies with grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "scores = cross_val_score(GridSearchCV(SVC(), param_grid, cv=5),\n",
    "                         iris.data, iris.target, cv=5)\n",
    "print(\"Cross-validation scores: \", scores)\n",
    "print(\"Mean cross-validation score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv(X, y, inner_cv, outer_cv, Classifier, parameter_grid):\n",
    "    outer_scores = []\n",
    "    # for each split of the data in the outer cross-validation\n",
    "    # (split method returns indices of training and test parts)\n",
    "    for training_samples, test_samples in outer_cv.split(X, y):\n",
    "        # find best parameter using inner cross-validation\n",
    "        best_parms = {}\n",
    "        best_score = -np.inf\n",
    "        # iterate over parameters\n",
    "        for parameters in parameter_grid:\n",
    "            # accumulate score over inner splits\n",
    "            cv_scores = []\n",
    "            # iterate over inner cross-validation\n",
    "            for inner_train, inner_test in inner_cv.split(\n",
    "                    X[training_samples], y[training_samples]):\n",
    "                # build classifier given parameters and training data\n",
    "                clf = Classifier(**parameters)\n",
    "                clf.fit(X[inner_train], y[inner_train])\n",
    "                # evaluate on inner test set\n",
    "                score = clf.score(X[inner_test], y[inner_test])\n",
    "                cv_scores.append(score)\n",
    "            # compute mean score over inner folds\n",
    "            mean_score = np.mean(cv_scores)\n",
    "            if mean_score > best_score:\n",
    "                # if better than so far, remember parameters\n",
    "                best_score = mean_score\n",
    "                best_params = parameters\n",
    "        # build classifier on best parameters using outer training set\n",
    "        clf = Classifier(**best_params)\n",
    "        clf.fit(X[training_samples], y[training_samples])\n",
    "        # evaluate\n",
    "        outer_scores.append(clf.score(X[test_samples], y[test_samples]))\n",
    "    return np.array(outer_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid, StratifiedKFold\n",
    "scores = nested_cv(iris.data, iris.target, StratifiedKFold(5),\n",
    "                   StratifiedKFold(5), SVC, ParameterGrid(param_grid))\n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parallelizing cross-validation and grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics and Scoring\n",
    "#### Keep the End Goal in Mind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics for Binary Classification\n",
    "##### Kinds of errors\n",
    "##### Imbalanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "y = digits.target == 9\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_majority = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "pred_most_frequent = dummy_majority.predict(X_test)\n",
    "print(\"Unique predicted labels: {}\".format(np.unique(pred_most_frequent)))\n",
    "print(\"Test score: {:.2f}\".format(dummy_majority.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=2).fit(X_train, y_train)\n",
    "pred_tree = tree.predict(X_test)\n",
    "print(\"Test score: {:.2f}\".format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dummy = DummyClassifier().fit(X_train, y_train)\n",
    "pred_dummy = dummy.predict(X_test)\n",
    "print(\"dummy score: {:.2f}\".format(dummy.score(X_test, y_test)))\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000, C=0.1).fit(X_train, y_train)\n",
    "pred_logreg = logreg.predict(X_test)\n",
    "print(\"logreg score: {:.2f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(y_test, pred_logreg)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_confusion_matrix_illustration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_binary_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Most frequent class:\")\n",
    "print(confusion_matrix(y_test, pred_most_frequent))\n",
    "print(\"\\nDummy model:\")\n",
    "print(confusion_matrix(y_test, pred_dummy))\n",
    "print(\"\\nDecision tree:\")\n",
    "print(confusion_matrix(y_test, pred_tree))\n",
    "print(\"\\nLogistic Regression\")\n",
    "print(confusion_matrix(y_test, pred_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Relation to accuracy\n",
    "\\begin{equation}\n",
    "\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision, recall and f-score\n",
    "\\begin{equation}\n",
    "\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "\\begin{equation}\n",
    "\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\text{F} = 2 \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(\"f1 score most frequent: {:.2f}\".format(\n",
    "    f1_score(y_test, pred_most_frequent)))\n",
    "print(\"f1 score dummy: {:.2f}\".format(f1_score(y_test, pred_dummy)))\n",
    "print(\"f1 score tree: {:.2f}\".format(f1_score(y_test, pred_tree)))\n",
    "print(\"f1 score logistic regression: {:.2f}\".format(\n",
    "    f1_score(y_test, pred_logreg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred_most_frequent,\n",
    "                            target_names=[\"not nine\", \"nine\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_dummy,\n",
    "                            target_names=[\"not nine\", \"nine\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_logreg,\n",
    "                            target_names=[\"not nine\", \"nine\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Taking uncertainty into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=(400, 50), cluster_std=[7.0, 2],\n",
    "                  random_state=22)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "svc = SVC(gamma=.05).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_decision_threshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, svc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lower_threshold = svc.decision_function(X_test) > -.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_lower_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision-Recall curves and ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precision, recall, thresholds = precision_recall_curve(\n",
    "    y_test, svc.decision_function(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use more data points for a smoother curve\n",
    "X, y = make_blobs(n_samples=(4000, 500), cluster_std=[7.0, 2], random_state=22)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "svc = SVC(gamma=.05).fit(X_train, y_train)\n",
    "precision, recall, thresholds = precision_recall_curve(\n",
    "    y_test, svc.decision_function(X_test))\n",
    "# find threshold closest to zero\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(precision[close_zero], recall[close_zero], 'o', markersize=10,\n",
    "         label=\"threshold zero\", fillstyle=\"none\", c='k', mew=2)\n",
    "\n",
    "plt.plot(precision, recall, label=\"precision recall curve\")\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0, max_features=2)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# RandomForestClassifier has predict_proba, but not decision_function\n",
    "precision_rf, recall_rf, thresholds_rf = precision_recall_curve(\n",
    "    y_test, rf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "plt.plot(precision, recall, label=\"svc\")\n",
    "\n",
    "plt.plot(precision[close_zero], recall[close_zero], 'o', markersize=10,\n",
    "         label=\"threshold zero svc\", fillstyle=\"none\", c='k', mew=2)\n",
    "\n",
    "plt.plot(precision_rf, recall_rf, label=\"rf\")\n",
    "\n",
    "close_default_rf = np.argmin(np.abs(thresholds_rf - 0.5))\n",
    "plt.plot(precision_rf[close_default_rf], recall_rf[close_default_rf], '^', c='k',\n",
    "         markersize=10, label=\"threshold 0.5 rf\", fillstyle=\"none\", mew=2)\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"f1_score of random forest: {:.3f}\".format(\n",
    "    f1_score(y_test, rf.predict(X_test))))\n",
    "print(\"f1_score of svc: {:.3f}\".format(f1_score(y_test, svc.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "ap_rf = average_precision_score(y_test, rf.predict_proba(X_test)[:, 1])\n",
    "ap_svc = average_precision_score(y_test, svc.decision_function(X_test))\n",
    "print(\"Average precision of random forest: {:.3f}\".format(ap_rf))\n",
    "print(\"Average precision of svc: {:.3f}\".format(ap_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Receiver Operating Characteristics (ROC) and AUC\n",
    "\\begin{equation}\n",
    "\\text{FPR} = \\frac{\\text{FP}}{\\text{FP} + \\text{TN}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, svc.decision_function(X_test))\n",
    "\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "# find threshold closest to zero\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize=10,\n",
    "         label=\"threshold zero\", fillstyle=\"none\", c='k', mew=2)\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, rf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve SVC\")\n",
    "plt.plot(fpr_rf, tpr_rf, label=\"ROC Curve RF\")\n",
    "\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize=10,\n",
    "         label=\"threshold zero SVC\", fillstyle=\"none\", c='k', mew=2)\n",
    "close_default_rf = np.argmin(np.abs(thresholds_rf - 0.5))\n",
    "plt.plot(fpr_rf[close_default_rf], tpr[close_default_rf], '^', markersize=10,\n",
    "         label=\"threshold 0.5 RF\", fillstyle=\"none\", c='k', mew=2)\n",
    "\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "rf_auc = roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1])\n",
    "svc_auc = roc_auc_score(y_test, svc.decision_function(X_test))\n",
    "print(\"AUC for Random Forest: {:.3f}\".format(rf_auc))\n",
    "print(\"AUC for SVC: {:.3f}\".format(svc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = digits.target == 9\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data, y, random_state=0)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for gamma in [1, 0.05, 0.01]:\n",
    "    svc = SVC(gamma=gamma).fit(X_train, y_train)\n",
    "    accuracy = svc.score(X_test, y_test)\n",
    "    auc = roc_auc_score(y_test, svc.decision_function(X_test))\n",
    "    fpr, tpr, _ = roc_curve(y_test , svc.decision_function(X_test))\n",
    "    print(\"gamma = {:.2f}  accuracy = {:.2f}  AUC = {:.2f}\".format(\n",
    "          gamma, accuracy, auc))\n",
    "    plt.plot(fpr, tpr, label=\"gamma={:.3f}\".format(gamma))\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.xlim(-0.01, 1)\n",
    "plt.ylim(0, 1.02)\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics for Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data, digits.target, random_state=0)\n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "pred = lr.predict(X_test)\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion_matrix(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "scores_image = mglearn.tools.heatmap(\n",
    "    confusion_matrix(y_test, pred), xlabel='Predicted label',\n",
    "    ylabel='True label', xticklabels=digits.target_names,\n",
    "    yticklabels=digits.target_names, cmap=plt.cm.gray_r, fmt=\"%d\")\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Micro average f1 score: {:.3f}\".format(\n",
    "    f1_score(y_test, pred, average=\"micro\")))\n",
    "print(\"Macro average f1 score: {:.3f}\".format(\n",
    "    f1_score(y_test, pred, average=\"macro\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using evaluation metrics in model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default scoring for classification is accuracy\n",
    "print(\"Default scoring: {}\".format(\n",
    "    cross_val_score(SVC(), digits.data, digits.target == 9, cv=5)))\n",
    "# providing scoring=\"accuracy\" doesn't change the results\n",
    "explicit_accuracy =  cross_val_score(SVC(), digits.data, digits.target == 9,\n",
    "                                     scoring=\"accuracy\", cv=5)\n",
    "print(\"Explicit accuracy scoring: {}\".format(explicit_accuracy))\n",
    "roc_auc =  cross_val_score(SVC(), digits.data, digits.target == 9,\n",
    "                           scoring=\"roc_auc\", cv=5)\n",
    "print(\"AUC scoring: {}\".format(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cross_validate(SVC(), digits.data, digits.target == 9,\n",
    "                     scoring=[\"accuracy\", \"roc_auc\", \"recall_macro\"],\n",
    "                     return_train_score=True, cv=5)\n",
    "display(pd.DataFrame(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data, digits.target == 9, random_state=0)\n",
    "\n",
    "# we provide a somewhat bad grid to illustrate the point:\n",
    "param_grid = {'gamma': [0.0001, 0.01, 0.1, 1, 10]}\n",
    "# using the default scoring of accuracy:\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Grid-Search with accuracy\")\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best cross-validation score (accuracy)): {:.3f}\".format(grid.best_score_))\n",
    "print(\"Test set AUC: {:.3f}\".format(\n",
    "    roc_auc_score(y_test, grid.decision_function(X_test))))\n",
    "print(\"Test set accuracy: {:.3f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using AUC scoring instead:\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, scoring=\"roc_auc\")\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"\\nGrid-Search with AUC\")\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best cross-validation score (AUC): {:.3f}\".format(grid.best_score_))\n",
    "print(\"Test set AUC: {:.3f}\".format(\n",
    "    roc_auc_score(y_test, grid.decision_function(X_test))))\n",
    "print(\"Test set accuracy: {:.3f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import SCORERS\n",
    "print(\"Available scorers:\")\n",
    "print(sorted(SCORERS.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary and Outlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
